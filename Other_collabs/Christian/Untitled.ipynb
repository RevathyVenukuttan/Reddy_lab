{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/reddylab/Revathy/scripts/generate_non_targeting_gRNAs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /data/reddylab/Revathy/scripts/generate_non_targeting_gRNAs.py\n",
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from Bio.Seq import Seq\n",
    "from random import random\n",
    "from scipy.stats import itemfreq\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, \\\n",
    "description=\"\"\"\n",
    "\n",
    "generate_non_targeting_gRNAs.py\n",
    "\n",
    "Given a list of targeting guides, this script generates a list of \n",
    "non-targeting guides depending on the number of samples specified \n",
    "in the --n_random_samples argument. \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "## required args: \n",
    "\n",
    "parser.add_argument(\"--gRNAs\", help=\"\"\"required, .txt file containing the list of targeting guide RNAs\"\"\",\n",
    "                     required=True)\n",
    "\n",
    "parser.add_argument(\"-n\", \"--n_random_samples\", type=int,\n",
    "                    help=\"\"\"required, number of random samples of non-targeting guides to be \n",
    "                    generated from the list of targeting guides given\"\"\", required=True)\n",
    "\n",
    "parser.add_argument(\"-o\", \"--output_dir\", help=\"\"\"required, path to the directory where the output of the script\n",
    "                    will be written into.\"\"\", required=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "#######################################################################################################\n",
    "\n",
    "## optional args:\n",
    "\n",
    "parser.add_argument(\"--path_tmp_files\", type=str, default=args.output_dir,\n",
    "                    help=\"\"\"path to all temporary files created for and during bowtie alignment\"\"\",\n",
    "                    dest=\"path_tmp_files\")\n",
    "parser.add_argument(\"--bowtie_index\", type=str, default='/data/reddylab/Reference_Data/Genomes/hg19/hg19',\n",
    "                    help=\"\"\"path to the directory that contains all the index files required for bowtie \n",
    "                    to perform alignment for the particular reference genome. The default is for the hg19\n",
    "                    human genome but can be changed to any other genome.\"\"\", dest=\"bowtie_index\")\n",
    "parser.add_argument(\"--runname\", type=str, default='NT_guides_generation',\n",
    "                    help=\"\"\"name of all the temporary files that will be created using the bowtie\n",
    "                    alignment\"\"\", dest=\"runname\")\n",
    "parser.add_argument(\"--btThreshold\", type=int, default=31,\n",
    "                    help=\"\"\"Threshold for bowtie\"\"\", dest='btThreshold')\n",
    "parser.add_argument(\"--mFlag\", type=int, default=1,\n",
    "                    help=\"\"\"Threshold for number of mismatches allowed in alignment\"\"\", dest='mFlag')\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "global DNA_ALPHABET\n",
    "DNA_ALPHABET = ['A','T','G','C']\n",
    "\n",
    "def extract_freq_from_np_uniq(a):\n",
    "    freqs = dict(zip(DNA_ALPHABET, np.zeros(4)))\n",
    "    kk,vv = np.unique(a, return_counts=True)\n",
    "    freqs.update(dict(zip(kk, (1.*vv)/a.shape[0])))\n",
    "    return [freqs[k] for k in DNA_ALPHABET]\n",
    "\n",
    "\n",
    "def subsample_alphabet_given_freqs(freqs):\n",
    "    return np.random.choice(DNA_ALPHABET, p=freqs)\n",
    "\n",
    "\n",
    "def outputTempBowtieFastq(libraryTable, outputFileName):\n",
    "    phredString = 'I4!=======44444+++++++' #weighting for how impactful mismatches are along sgRNA sequence \n",
    "    with open(outputFileName,'w') as outfile:\n",
    "        for name, row in libraryTable.iterrows():\n",
    "            outfile.write('@' + name + '\\n')\n",
    "            outfile.write('CCN' + str(Seq(row['sequence'][1:]).reverse_complement()) + '\\n')\n",
    "            outfile.write('+\\n')\n",
    "            outfile.write(phredString + '\\n')\n",
    "\n",
    "            \n",
    "### setting arguments to variables\n",
    "\n",
    "n_random_samples = args.n_random_samples\n",
    "file_name = args.gRNAs.split('/')[-1].split('.')[0]\n",
    "fqFile = args.path_tmp_files + '/' + 'temp.fastq'\n",
    "alignmentList = [(args.btThreshold, args.mFlag, args.bowtie_index, args.runname)]\n",
    "\n",
    "\n",
    "#### reading the input targeting GRNA file\n",
    "grnas = pd.read_csv(args.gRNAs, sep=',', names = [\"gRNA\"])\n",
    "grnas[\"gRNA\"] = grnas[\"gRNA\"].str.upper()\n",
    "\n",
    "\n",
    "\n",
    "freqs = np.apply_along_axis(extract_freq_from_np_uniq, 0, \n",
    "                            np.vstack([list(t) for t in grnas.gRNA.values.T]))\n",
    "\n",
    "nt_final_set = set()\n",
    "alignmentColumns = []\n",
    "while len(nt_final_set)<n_random_samples:\n",
    "    random_samples = [''.join(np.apply_along_axis(subsample_alphabet_given_freqs, 0,  freqs)) for ii in range(n_random_samples)]\n",
    "    negTable = pd.DataFrame(random_samples, \n",
    "                            index=['NT_%d' %i  for i in range(1, len(random_samples)+1)], \n",
    "                            columns = ['sequence'])\n",
    "    outputTempBowtieFastq(negTable, fqFile)\n",
    "\n",
    "    for btThreshold, mflag, bowtieIndex, runname in alignmentList:\n",
    "\n",
    "        alignedFile = args.path_tmp_files + '/' + args.runname + '_aligned.txt'\n",
    "        unalignedFile = args.path_tmp_files + '/' + args.runname + '_unaligned.fq'\n",
    "        maxFile = args.path_tmp_files + '/' + args.runname + '_max.fq'\n",
    "\n",
    "        bowtieString = '/nfs/software/helmod/apps/Core/bowtie/1.1.1-fasrc01/bowtie -n 3 -l 5 -e ' + \\\n",
    "            str(btThreshold) + \\\n",
    "            ' -m ' + str(mflag) + \\\n",
    "            ' --nomaqround -a --tryhard -p 16 --chunkmbs 256 ' + \\\n",
    "            bowtieIndex + \\\n",
    "            ' --suppress 5,6,7 --un ' + \\\n",
    "            unalignedFile + \\\n",
    "            ' --max ' + maxFile + \\\n",
    "            ' -q ' + \\\n",
    "            fqFile + ' ' + \\\n",
    "            alignedFile\n",
    "\n",
    "        subprocess.call(bowtieString, shell=True)\n",
    "\n",
    "        #read unaligned file for negs, and then don't flip boolean of alignmentTable\n",
    "        with open(unalignedFile) as infile:\n",
    "            sgsAligning = set()\n",
    "            for i, line in enumerate(infile):\n",
    "                if i%4 == 0: #id line\n",
    "                    sgsAligning.add(line.strip()[1:])\n",
    "\n",
    "        alignmentColumns.append(negTable.apply(lambda row: row.name in sgsAligning, axis=1))\n",
    "\n",
    "    alignmentTable = pd.concat(alignmentColumns,axis=1, keys=list(zip(*alignmentList))[3])\n",
    "\n",
    "    nt_final_set = set(list(nt_final_set) + list(negTable[alignmentTable.values].values.T[0]))\n",
    "\n",
    "nt_final_df = pd.DataFrame(list(nt_final_set), columns=['nt_sequence'])\n",
    "nt_final_df.to_csv(args.output_dir + '/' + file_name + '_NT_guides.txt', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Final_Lib_Protospacers'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test='/data/reddylab/Revathy/collabs/Grayson/Final_Lib_Protospacers.txt'\n",
    "test.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/reddylab/Revathy/collabs/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# reads processed: 500\n",
      "# reads with at least one reported alignment: 100 (20.00%)\n",
      "# reads that failed to align: 267 (53.40%)\n",
      "# reads with alignments suppressed due to -m: 133 (26.60%)\n",
      "Reported 100 alignments to 1 output stream(s)\n",
      "# reads processed: 500\n",
      "# reads with at least one reported alignment: 109 (21.80%)\n",
      "# reads that failed to align: 262 (52.40%)\n",
      "# reads with alignments suppressed due to -m: 129 (25.80%)\n",
      "Reported 109 alignments to 1 output stream(s)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /data/reddylab/software/miniconda3/bin/activate revathy_py3\n",
    "mkdir -p /data/reddylab/Revathy/collabs/test\n",
    "python /data/reddylab/Revathy/scripts/generate_non_targeting_gRNAs.py \\\n",
    "--gRNAs /data/reddylab/Revathy/collabs/Grayson/Final_Lib_Protospacers.txt \\\n",
    "-n 500 \\\n",
    "-o /data/reddylab/Revathy/collabs/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (revathy)",
   "language": "python",
   "name": "revathy_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
