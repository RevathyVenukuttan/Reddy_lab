{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/scripts/process_STARR.r\n"
     ]
    }
   ],
   "source": [
    "%%writefile /data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/scripts/process_STARR.r\n",
    "#!/usr/bin/env Rscript\n",
    "\n",
    "suppressPackageStartupMessages({\n",
    "    library(Rsamtools)\n",
    "    library(GenomicAlignments)\n",
    "    library(GenomicFiles)\n",
    "    library(optparse)\n",
    "    library(data.table)\n",
    "    library(optparse)\n",
    "    library(rtracklayer)\n",
    "    library(GenomicRanges)\n",
    "    library(RColorBrewer)\n",
    "    library(doParallel)\n",
    "    library(argparse)\n",
    "});\n",
    "\n",
    "# create parser object and add parser arguments\n",
    "parser <- ArgumentParser()\n",
    "\n",
    "parser$add_argument(\"-i\", \"--input\", nargs=\"+\", help=\"BAM files with reads\")\n",
    "parser$add_argument(\"-p\", \"--cores\", default=4, help=\"Number of cores to use in multicore processing\")\n",
    "parser$add_argument(\"--UMI\", required=F, action=\"store_true\", default=FALSE, help=\"Specify if UMI/barcode present for fragments\")\n",
    "parser$add_argument(\"-o\", \"--outfile\", required=F, help=\"Output filename to create bed file.\")\n",
    "\n",
    "args <- parser$parse_args()\n",
    "\n",
    "\n",
    "registerDoParallel(cores=args$cores);\n",
    "\n",
    "# Shorthand for \"pretty number\" formatting\n",
    "pn = function(value) {\n",
    "    prettyNum(value, big.mark=\",\")\n",
    "}\n",
    "\n",
    "# Shorthand to print the full argument list\n",
    "msgout = function(...) {\n",
    "    write(paste(...), stdout());\n",
    "}\n",
    "\n",
    "if (!(args$UMI)){\n",
    "    bfilters = ScanBamParam(mapqFilter=10, flag=scanBamFlag(isSecondaryAlignment=F));\n",
    "} else {\n",
    "    bfilters = ScanBamParam(mapqFilter=10, flag=scanBamFlag(isSecondaryAlignment=F, isDuplicate=F));\n",
    "}\n",
    "\n",
    "count_reads = function(reads) {\n",
    "    uniq = unique(reads);\n",
    "    # sum over duplicates to get a count for each unique 5'/3' end\n",
    "    uniq$count = countOverlaps( uniq, reads, type=\"equal\" );\n",
    "    return( uniq );\n",
    "}\n",
    "\n",
    "yield.bam = function(X) {\n",
    "    y = GRanges( readGAlignmentPairs(X, use.names=F, param=bfilters ));\n",
    "    return(y);\n",
    "}\n",
    "\n",
    "map.bam = function(X) {\n",
    "    return(X);\n",
    "}\n",
    "\n",
    "reduce.bam = function(x, y) {\n",
    "    x = append(x, y);\n",
    "    # print the number of readpairs processed\n",
    "    msgout(pn(length(x)), 'mapped human reads');\n",
    "    return(x);\n",
    "}\n",
    "\n",
    "merge_counts = function( x, y, name ) {\n",
    "    if(length(x)) {\n",
    "        hits = findOverlaps(x, y, type=\"equal\");\n",
    "        mcols(x)[hits@from, name] = mcols(x)[hits@from, name] + mcols(y)[hits@to, name];\n",
    "        y = y[-hits@to,];\n",
    "        for( cn in colnames(mcols(x))) {\n",
    "            if( !cn %in% colnames(mcols(y)) ) {\n",
    "                mcols(y)[,cn] = 0;\n",
    "            }\n",
    "        }\n",
    "        mcols(y) = mcols(y)[,colnames(mcols(x))];\n",
    "        colnames(mcols(y)) = colnames(mcols(x));\n",
    "    }\n",
    "    return(append(x, y));\n",
    "}\n",
    "\n",
    "\n",
    "ctFile = args$input;\n",
    "msgout( \"Processing \", ctFile );\n",
    "infile = BamFile(ctFile, yieldSize=1 * 10^6, asMates=T );\n",
    "aligned = reduceByYield( infile, yield.bam, map.bam, reduce.bam, parallel=F );\n",
    "\n",
    "#msgout(pn(length(aligned)), 'mapped reads');\n",
    "\n",
    "# compute coverage from identical reads => 'count' column\n",
    "seqlib = count_reads(aligned);\n",
    "print(seqlib)\n",
    "\n",
    "# convert the GRanges object to dataframe and add columns corresponding to name, score and barcode information\n",
    "# as per the common file format needed\n",
    "\n",
    "seqlib = as.data.frame(seqlib)\n",
    "cols_to_add = data.frame(name=paste0(seqlib$seqnames,\"_\", seqlib$start,\"_\",seqlib$end), \n",
    "                         score = pmin(seqlib$count,1000), \n",
    "                         barcode = '.')\n",
    "\n",
    "seqlib_df = cbind(seqlib, cols_to_add)\n",
    "col_order = c('seqnames','start','end','name','score','strand','count','barcode')\n",
    "seqlib_df = seqlib_df[, col_order]\n",
    "\n",
    "# write the dataframe into a bed file\n",
    "\n",
    "write.table(seqlib_df, file=paste0(args$outfile), quote=FALSE, sep='\\t');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 24998610\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /data/reddylab/software/miniconda3/bin/activate alex_py3\n",
    "mkdir -p /data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/count\n",
    "sbatch -pnew,all \\\n",
    "    --array=0-6 \\\n",
    "    --output=/data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/logs/process_STARR.%a.out \\\n",
    "    --cpus-per-task 8 \\\n",
    "    --mem 64G \\\n",
    "    <<'EOF'\n",
    "#!/bin/bash\n",
    "FILES=($(/bin/ls -1 /bin/ls -1 /data/reddylab/Alex/encode4_duke/data/data_distribution/bam/*bam))\n",
    "INFILE=${FILES[${SLURM_ARRAY_TASK_ID}]}\n",
    "INFILE_ROOTNAME=$(basename ${INFILE})\n",
    "echo \"Processing ${INFILE}: saving to ${INFILE_ROOTNAME/.bam/.Rdata}\"\n",
    "Rscript /data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/scripts/process_STARR.r \\\n",
    "    -i ${INFILE} \\\n",
    "    --UMI \\\n",
    "    -o /data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/count/${INFILE_ROOTNAME/.bam/.bed} \n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/scripts/import_STARR.r\n"
     ]
    }
   ],
   "source": [
    "%%writefile /data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/scripts/import_STARR.r\n",
    "\n",
    "#!/usr/bin/env Rscript\n",
    "\n",
    "suppressPackageStartupMessages({\n",
    "    library(Rsamtools)\n",
    "    library(GenomicAlignments)\n",
    "    library(GenomicFiles)\n",
    "    library(data.table)\n",
    "    library(optparse)\n",
    "    library(rtracklayer)\n",
    "    library(GenomicRanges)\n",
    "    library(RColorBrewer)\n",
    "    library(doParallel)\n",
    "    library(argparse)\n",
    "});\n",
    "registerDoParallel(cores=7);\n",
    "\n",
    "## create parser object\n",
    "parser <- ArgumentParser()\n",
    "\n",
    "## add arguments for the ArgumentParser\n",
    "\n",
    "parser$add_argument(\"-i\", \"--input\", nargs=\"+\", help=\"Input .RData files\")\n",
    "parser$add_argument(\"-col\", \"--col-names\", nargs=\"+\", help=\"Column names for the files\")\n",
    "#parser$add_argument(\"-p\", \"--cores\", default=4, help=\"Number of cores to use in multicore processing\")\n",
    "parser$add_argument(\"-o\", \"--outfile\", nargs=\"+\", help=\"Output file name to create the .txt file\")\n",
    "args <- parser$parse_args()\n",
    "\n",
    "#registerDoParallel(cores=args$cores);\n",
    "\n",
    "merge_counts = function( x, y, name ) {\n",
    "    if(length(x)) {\n",
    "        hits = findOverlaps(x, y, type=\"equal\");\n",
    "        mcols(x)[hits@from, name] = mcols(x)[hits@from, name] + mcols(y)[hits@to, name];\n",
    "        y = y[-hits@to,];\n",
    "        for( cn in colnames(mcols(x))) {\n",
    "            if( !cn %in% colnames(mcols(y)) ) {\n",
    "                mcols(y)[,cn] = 0;\n",
    "            }\n",
    "        }\n",
    "        mcols(y) = mcols(y)[,colnames(mcols(x))];\n",
    "        colnames(mcols(y)) = colnames(mcols(x));\n",
    "    }\n",
    "    return(append(x, y));\n",
    "}\n",
    "\n",
    "starr_count = GRanges();\n",
    "\n",
    "Samples = args$input;\n",
    "colName = args$col;\n",
    "\n",
    "for( i in 1:length(Samples) ) {\n",
    "    bcl = Samples[i];\n",
    "    bcn = colName[i];\n",
    "    message(bcn);\n",
    "    load(Samples[i]); ## path to each file\n",
    "    x = seqlib;\n",
    "    \n",
    "    colnames(mcols(x)) = c(bcn);\n",
    "    mcols(starr_count)[,bcn] = 0;\n",
    "    starr_count = merge_counts(starr_count, x, bcn)\n",
    "    print(starr_count)\n",
    "}\n",
    "\n",
    "write.table(starr_count, file=paste0(args$outfile), quote=FALSE, sep='\\t');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 24712281\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /data/reddylab/software/miniconda3/bin/activate alex_py3\n",
    "mkdir -p /data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/logs\n",
    "mkdir -p /data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/tmp\n",
    "sbatch -pnew,all \\\n",
    "    --output=/data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/logs/import_STARR.junke.out \\\n",
    "    --cpus-per-task 8 \\\n",
    "    --mem 50G \\\n",
    "    <<'EOF'\n",
    "#!/bin/bash\n",
    "FILES=($(/bin/ls -1 /data/reddylab/Alex/encode4_duke/ipynbs/jamborees/20210222_MPRA_STARR_Jamboree/tmp/*Rdata))\n",
    "INFILE=${FILES[${SLURM_ARRAY_TASK_ID}]}\n",
    "INFILE_ROOTNAME=$(basename ${INFILE}| cut -d\".\" -f1,2)\n",
    "echo \"Processing ${INFILE}: saving to ${INFILE_ROOTNAME/.bam/.Rdata}\" \n",
    "Rscript /data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/scripts/import_STARR.r \\\n",
    "    -i ${FILES[*]} \\\n",
    "    -col \"inputRep1\" \"inputRep2\" \"inputRep3\" \"outputRep1\" \"outputRep2\" \"outputRep3\" \\\n",
    "    -o /data/reddylab/Revathy/dev/Jamborees/MPRA_STARRseq/tmp/${INFILE_ROOTNAME}.counts.txt\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "getBamFlags <- function(countAll) {\n",
    "        # get baminfo\n",
    "    if (isTRUE(countAll)) {\n",
    "        # if countAll given, count both reads (in PE mode) or all reads (in SE mode)\n",
    "        bamFlags <- scanBamFlag(\n",
    "                                isUnmappedQuery = FALSE,\n",
    "                                isSecondaryAlignment = FALSE\n",
    "                            )\n",
    "    } else {\n",
    "        # else count only R1 (in PE mode)\n",
    "        bamFlags <- scanBamFlag(\n",
    "                                isUnmappedQuery = FALSE,\n",
    "                                isFirstMateRead = TRUE,\n",
    "                                isSecondaryAlignment = FALSE\n",
    "                            )\n",
    "    }\n",
    "    return(bamFlags)\n",
    "}\n",
    "\n",
    "numReadsInBed <- function(regions, bams = NA, countall = FALSE) {\n",
    "    counts <-\n",
    "        GenomicAlignments::summarizeOverlaps(\n",
    "            GenomicRanges::GRangesList(regions),\n",
    "            reads = Rsamtools::BamFileList(as.character(bams)),\n",
    "            mode = \"Union\",\n",
    "            inter.feature = FALSE,\n",
    "            param = Rsamtools::ScanBamParam(flag = getBamFlags(countAll = countall))\n",
    "        )\n",
    "    numreads <- SummarizedExperiment::assay(counts)\n",
    "    return(t(numreads))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload data into synapse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'synapse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-148077c36b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msynapse\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0muploader\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'synapse' is not defined"
     ]
    }
   ],
   "source": [
    "synapse-uploader -h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
