{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/fs1/data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/results/tagAlign\n",
    "cd /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/results/tagAlign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "full_fragments_and_cell_type_labels = [(\"/data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/notebooks/fragment_files/syn52118183_syn52128237_GM12878_10XMultiome.atac.filter.fragments.hg38.tsv.gz/GM12878_10XMultiome.atac.filter.fragments.hg38.tsv.gz\",\n",
    "                                        \"/data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/results/GM12878_10xMultiome_cell_types.tsv.gz\")]\n",
    "os.chdir('/data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/results/tagAlign')\n",
    "local_clusters_fld = os.path.join(os.getcwd(),\"clusters\")\n",
    "os.makedirs(local_clusters_fld, exist_ok=True)\n",
    "local_path_to_download = os.path.join(os.getcwd(),\"fragment_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_file(filename):\n",
    "  print(\"remove_file method: {}\".format(filename))\n",
    "  if os.path.exists(filename):\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-cda854407611>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-cda854407611>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    print(f\"Split DataFrame for atac_dataset {group_id} saved to {file_name}\")\u001b[0m\n\u001b[0m                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%run /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/notebooks/tsv_files_utils_from_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fragment_line_string(string):\n",
    "    # Remove newline characters\n",
    "    string = string.replace(\"\\n\", \"\")\n",
    "\n",
    "    # Splitting by tab character\n",
    "    split_list = string.split(\"\\t\")\n",
    "\n",
    "    # Splitting the word before the last one by underscore\n",
    "    last_word = split_list[-2]\n",
    "    split_word = last_word.split(\"_\")\n",
    "\n",
    "    # Inserting the split word before the last one in the list\n",
    "    split_list.insert(-1, split_word[0])\n",
    "    split_list.insert(-1, split_word[1])\n",
    "\n",
    "    # Concatenating values at index 5 and index 4 with underscore\n",
    "    concatenated_value = split_list[5] + \"_\" + split_list[4]\n",
    "    split_list.append(concatenated_value)\n",
    "\n",
    "    return split_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fragment_line_to_tagAlign(r):\n",
    "#     chr1\t10007\t10175\tENCSR023FME_GAAGGTTCAAAGTGTCAGTCAA\t1\n",
    "    rows_str = \"\"\n",
    "    r_list = r.split(\"\\t\")\n",
    "    # print(\"r_list is {}\".format(r_list))\n",
    "    row1 = []\n",
    "    row2 = []\n",
    "\n",
    "    row1.append(r_list[0])\n",
    "    row1.append(r_list[1])\n",
    "    row1.append(str(int(r_list[1]) + 1))\n",
    "    row1.append(r_list[3])\n",
    "    row1.append('1')\n",
    "    row1.append('+')\n",
    "    # print(\"convert_to_tagAlign: row 1 is: {}\".format(row1))\n",
    "\n",
    "    row2.append(r_list[0])\n",
    "    row2.append(str(int(r_list[2]) - 1))\n",
    "    row2.append(r_list[2])\n",
    "    row2.append(r_list[3])\n",
    "    row2.append('1')\n",
    "    row2.append('-')\n",
    "    # print(\"convert_to_tagAlign: row 2 is: {}\".format(row2))\n",
    "    \n",
    "    rows_str = \"\\t\".join(row1)+\"\\n\"+\"\\t\".join(row2)+\"\\n\"\n",
    "    # print(\"rows_str is {}\".format(rows_str))\n",
    "    return rows_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsv_gz_file is /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/results/GM12878_10xMultiome_cell_types.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines(tsv_gz_file, comment_character='#'):\n",
    "    # Open the compressed file using gzip\n",
    "    print(\"tsv_gz_file is {}\".format(tsv_gz_file))\n",
    "    with gzip.open(tsv_gz_file, 'rt') as file:\n",
    "        # Skip comment lines and empty lines, and load the remaining data into a DataFrame\n",
    "        df = pd.read_csv(file, delimiter='\\t', comment=comment_character, skip_blank_lines=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "celltypes = read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines('/data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/results/GM12878_10xMultiome_cell_types.tsv.gz')\n",
    "celltypes[['barcode','cell','type']] = celltypes['cell_id'].str.split('_', expand=True)\n",
    "celltypes['id'] = celltypes['cell']+'_'+celltypes['barcode']\n",
    "celltypes.drop(columns=['cell_id','barcode','cell','type'], inplace=True)\n",
    "celltypes.rename(columns={'id':'cell_id'}, inplace=True)\n",
    "celltypes['cell_type_name'] = 'GM12878_10XMultiome'\n",
    "celltypes = celltypes[['cell_id','cell_type_id','cell_type_name','membership_score']]\n",
    "celltypes.to_csv('/data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/results/GM12878_10xMultiome_cell_types_v1.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcell_id\tcell_type_id\tcell_type_name\tmembership_score\r\n",
      "0\tGM12878_TGTGCTGAGCCTGATG\tGM12878_10XMultiome\tGM12878_10XMultiome\t\r\n",
      "1\tGM12878_TGACTTCGTAAGCTTG\tGM12878_10XMultiome\tGM12878_10XMultiome\t\r\n",
      "2\tGM12878_TACCGAAGTCCTTCTC\tGM12878_10XMultiome\tGM12878_10XMultiome\t\r\n",
      "3\tGM12878_CAAGTGAAGTTCCCAC\tGM12878_10XMultiome\tGM12878_10XMultiome\t\r\n",
      "4\tGM12878_AAGAATCAGCTCAAAC\tGM12878_10XMultiome\tGM12878_10XMultiome\t\r\n",
      "5\tGM12878_GGCGTTATCACGCATG\tGM12878_10XMultiome\tGM12878_10XMultiome\t\r\n",
      "6\tGM12878_ACAAACTGTTGGATAT\tGM12878_10XMultiome\tGM12878_10XMultiome\t\r\n",
      "7\tGM12878_GAAAGGCTCCCTGGAA\tGM12878_10XMultiome\tGM12878_10XMultiome\t\r\n",
      "8\tGM12878_GCAAGTGCATAATCCG\tGM12878_10XMultiome\tGM12878_10XMultiome\t\r\n"
     ]
    }
   ],
   "source": [
    "!zcat /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/results/GM12878_10xMultiome_cell_types_v1.tsv.gz | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t10005\t10387\tTTATTGCTCAGGCCTA_GM12878_10XMultiome\t1\r\n",
      "chr1\t10005\t10387\tGACTCACCACCGGTAT_GM12878_10XMultiome\t1\r\n",
      "chr1\t10006\t10356\tTTAAAGGCACAAAGAC_GM12878_10XMultiome\t1\r\n",
      "chr1\t10006\t10387\tTTTGACTTCTCAATGA_GM12878_10XMultiome\t1\r\n",
      "chr1\t10007\t10261\tAAATCCGGTCATAGAT_GM12878_10XMultiome\t1\r\n",
      "chr1\t10007\t10303\tACACTAATCGGGCCAT_GM12878_10XMultiome\t1\r\n",
      "chr1\t10007\t10387\tGCTGTACCAAAGCGGC_GM12878_10XMultiome\t1\r\n",
      "chr1\t10007\t10407\tTCTGTGACAACTAGCC_GM12878_10XMultiome\t1\r\n",
      "chr1\t10007\t10502\tGGTGCTGGTCACAGCG_GM12878_10XMultiome\t1\r\n",
      "chr1\t10012\t10114\tATTAGGTGTGAGCACT_GM12878_10XMultiome\t1\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!zcat /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/notebooks/fragment_files/syn52118183_syn52128237_GM12878_10XMultiome.atac.filter.fragments.hg38.tsv.gz/GM12878_10XMultiome.atac.filter.fragments.hg38.tsv.gz | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/notebooks/tagAlign_script.py\n",
    "#!/usr/bin/env python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/notebooks/tagAlign_script.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "full_fragments_and_cell_type_labels = [(\"/data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/notebooks/fragment_files/syn52118183_syn52128237_GM12878_10XMultiome.atac.filter.fragments.hg38.tsv.gz/GM12878_10XMultiome.atac.filter.fragments.hg38.tsv.gz\",\n",
    "                                        \"/data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/results/GM12878_10xMultiome_cell_types_v1.tsv.gz\")]\n",
    "\n",
    "local_clusters_fld = os.path.join(os.getcwd(),\"clusters\")\n",
    "os.makedirs(local_clusters_fld, exist_ok=True)\n",
    "local_path_to_download = os.path.join(os.getcwd(),\"fragment_files\")\n",
    "\n",
    "def remove_file(filename):\n",
    "    print(\"remove_file method: {}\".format(filename))\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "        \n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "def read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines(tsv_gz_file, comment_character='#'):\n",
    "    # Open the compressed file using gzip\n",
    "    print(\"tsv_gz_file is {}\".format(tsv_gz_file))\n",
    "    with gzip.open(tsv_gz_file, 'rt') as file:\n",
    "        # Skip comment lines and empty lines, and load the remaining data into a DataFrame\n",
    "        df = pd.read_csv(file, delimiter='\\t', comment=comment_character, skip_blank_lines=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# # Specify the path to the TSV.gz file\n",
    "# tsv_gz_file = '/path/to/file.tsv.gz'\n",
    "\n",
    "# # Read the TSV.gz file and create a DataFrame\n",
    "# dataframe = read_tsv_gz_to_dataframe(tsv_gz_file)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(dataframe)\n",
    "\n",
    "    \n",
    "def split_fragment_line_string(string):\n",
    "    # Remove newline characters\n",
    "    string = string.replace(\"\\n\", \"\")\n",
    "\n",
    "    # Splitting by tab character\n",
    "    split_list = string.split(\"\\t\")\n",
    "\n",
    "    # Splitting the word before the last one by underscore\n",
    "    last_word = split_list[-2]\n",
    "    split_word = last_word.split(\"_\")\n",
    "\n",
    "    # Inserting the split word before the last one in the list\n",
    "    split_list.insert(-1, split_word[0])\n",
    "    split_list.insert(-1, split_word[1])\n",
    "\n",
    "    # Concatenating values at index 5 and index 4 with underscore\n",
    "    concatenated_value = split_list[5] + \"_\" + split_list[4]\n",
    "    split_list.append(concatenated_value)\n",
    "\n",
    "    return split_list\n",
    "\n",
    "def convert_fragment_line_to_tagAlign(r):\n",
    "#     chr1\t10007\t10175\tENCSR023FME_GAAGGTTCAAAGTGTCAGTCAA\t1\n",
    "    rows_str = \"\"\n",
    "    r_list = r.split(\"\\t\")\n",
    "    # print(\"r_list is {}\".format(r_list))\n",
    "    row1 = []\n",
    "    row2 = []\n",
    "\n",
    "    row1.append(r_list[0])\n",
    "    row1.append(r_list[1])\n",
    "    row1.append(str(int(r_list[1]) + 1))\n",
    "    row1.append(r_list[3])\n",
    "    row1.append('1')\n",
    "    row1.append('+')\n",
    "    # print(\"convert_to_tagAlign: row 1 is: {}\".format(row1))\n",
    "\n",
    "    row2.append(r_list[0])\n",
    "    row2.append(str(int(r_list[2]) - 1))\n",
    "    row2.append(r_list[2])\n",
    "    row2.append(r_list[3])\n",
    "    row2.append('1')\n",
    "    row2.append('-')\n",
    "    # print(\"convert_to_tagAlign: row 2 is: {}\".format(row2))\n",
    "    \n",
    "    rows_str = \"\\t\".join(row1)+\"\\n\"+\"\\t\".join(row2)+\"\\n\"\n",
    "    # print(\"rows_str is {}\".format(rows_str))\n",
    "    return rows_str\n",
    "\n",
    "\n",
    "for local_file_tuple in full_fragments_and_cell_type_labels:\n",
    "\n",
    "    # Dictionary to store the output file handles with names\n",
    "    output_handles = {}\n",
    "    local_fragment_file = local_file_tuple[0]\n",
    "    full_cell_types_annotation_file_path = local_file_tuple[1]\n",
    "    print(\"!!!!!local_fragment_file is {}\".format(local_fragment_file))\n",
    "    file_atac_dataset_id = local_fragment_file.split(\"/\")[10].split('.')[0]\n",
    "    print(\"file_atac_dataset_id is {}\".format(file_atac_dataset_id))\n",
    " \n",
    "    # This full_cell_types_annotation_file_path was given as an input\n",
    "    df_cell_types_for_atac_dataset = read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines(full_cell_types_annotation_file_path)\n",
    "    cell_type_id_names_for_atac_dataset = list(set(df_cell_types_for_atac_dataset['cell_type_id']))\n",
    "    print(\"number of cell_type_id_names_for_atac_dataset is {}\".format(len(cell_type_id_names_for_atac_dataset)))\n",
    "    # List of output text files with corresponding names\n",
    "    # [(\"output1.txt\", \"file_1\"), (\"output2.txt\", \"file_2\"), (\"output3.txt\", \"file_3\")]\n",
    "    output_tagAlign_files_with_names = [(os.path.join(local_clusters_fld,file_atac_dataset_id,\"tagAlign_{}_{}.tsv\".format(file_atac_dataset_id,cell_type_name_id)),\n",
    "                                        cell_type_name_id) for cell_type_name_id in cell_type_id_names_for_atac_dataset]\n",
    "\n",
    "\n",
    "    # this will make sure that we will not run the same tagAlign twice.\n",
    "    tagAlign_exists = [os.path.exists(output_tagAlign_file[0]) for output_tagAlign_file in output_tagAlign_files_with_names]\n",
    "    print(\"tagAlign_exists is {}\".format(tagAlign_exists))\n",
    "#     if sum(tagAlign_exists) >0:\n",
    "#         print(\"output_tagAlign_files_with_names {} is at work or was already downloaded. continue\".format(output_tagAlign_files_with_names))\n",
    "#         continue # either started by annother process or already was processed\n",
    "#     else:\n",
    "    print(\"!!!output_tagAlign_files_with_names {}. open files\".format(output_tagAlign_files_with_names))\n",
    "    for tag_file_path, tag_file_cell_type_name in output_tagAlign_files_with_names:\n",
    "#         print(\"tag_file_path is {}\".format(tag_file_path))\n",
    "#         print(\"os.path.dirname(tag_file_path) is {}\".format(os.path.dirname(tag_file_path)))\n",
    "        os.makedirs(os.path.dirname(tag_file_path), exist_ok=True)\n",
    "        output_handles[tag_file_cell_type_name] = open(tag_file_path, \"w\")\n",
    "\n",
    "    # print(\"!!!output_tagAlign_files_with_names {}\".format(output_tagAlign_files_with_names))\n",
    "    print(\"open local_fragment_file {}\".format(local_fragment_file))\n",
    "    with gzip.open(local_fragment_file, \"rt\") as infile:\n",
    "        missing_bc = 0\n",
    "        # Open the output files and store their handles in the list\n",
    "        num_of_lines_written=0\n",
    "        for line_number, line in enumerate(infile, start=1):\n",
    "            # debug\n",
    "#             if line_number > 20:\n",
    "#                 continue \n",
    "\n",
    "            # here cases where bc_datasetId or datasetId_bc are being mixed between the fragments and the\n",
    "            # cell type are being address. you can select the righ out_list for your experiment\n",
    "            out_list = split_fragment_line_string(line)\n",
    "            bc = out_list[-1]\n",
    "\n",
    "\n",
    "#             Austin output: chrom, start, end, bc, rem = line.rstrip('\\n').split('\\t', 5)\n",
    "            out_line_to_print = \"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(out_list[0],out_list[1],out_list[2],bc,out_list[-2])\n",
    "#             chr1\t10007\t10175\tENCSR023FME#ENCSR023FME_GAAGGTTCAAAGTGTCAGTCAA\t1\n",
    "            num_of_lines_written +=1\n",
    "            returnTagAlign = convert_fragment_line_to_tagAlign(out_line_to_print)\n",
    "\n",
    "            # write to the relevant cell type file\n",
    "            # print(\"df_cell_types_for_atac_dataset[cell_id][0:5] is {}\".format(df_cell_types_for_atac_dataset['cell_id'][0:5]))\n",
    "            bc_exists_in_cell_type_atac_dataset = df_cell_types_for_atac_dataset[df_cell_types_for_atac_dataset['cell_id']==bc]\n",
    "            # print(\"len(bc_exists_in_cell_type_atac_dataset) is {} for bc {}\".format(len(bc_exists_in_cell_type_atac_dataset),bc))\n",
    "            if len(bc_exists_in_cell_type_atac_dataset) ==1:\n",
    "                tag_file_cell_type_id = df_cell_types_for_atac_dataset.loc[df_cell_types_for_atac_dataset['cell_id'] == bc, 'cell_type_id'].iloc[0]\n",
    "                # print(\"tag_file_cell_type_id is {}\".format(tag_file_cell_type_id))\n",
    "                output_handles[tag_file_cell_type_id].write(returnTagAlign)\n",
    "            else:\n",
    "                missing_bc+=1\n",
    "\n",
    "        for tag_file_path, tag_file_cell_type_name in output_tagAlign_files_with_names:\n",
    "            print(\"tag_file_path is {}\".format(tag_file_path))\n",
    "            output_handles[tag_file_cell_type_name].close()    \n",
    "        print(\"finished clustering local_fragment_file {} by cell type. for types {}\".format(local_fragment_file, cell_type_id_names_for_atac_dataset))\n",
    "        print(\"total missing bc are {}\".format(missing_bc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 30172596\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/logs\n",
    "sbatch -p all \\\n",
    "    --cpus-per-task 16 \\\n",
    "    --mem 64G \\\n",
    "    -o /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/logs/tagAlign.out \\\n",
    "    <<'EOF'\n",
    "#!/bin/bash\n",
    "python /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/notebooks/tagAlign_script.py\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "          30172518       all spawner-    rv103  R    7:30:21      1 dl-01\r\n",
      "          30172596       all   sbatch    rv103  R    1:18:25      1 dl-01\r\n",
      "        30172602_0       all   sbatch    rv103  R      30:08      1 x1-03-2\r\n",
      "        30172602_1       all   sbatch    rv103  R      30:08      1 x1-03-3\r\n",
      "        30172602_2       all   sbatch    rv103  R      30:08      1 x1-03-3\r\n",
      "        30172602_3       all   sbatch    rv103  R      30:08      1 x1-03-4\r\n",
      "        30172602_4       all   sbatch    rv103  R      30:08      1 x1-02-3\r\n",
      "        30172602_5       all   sbatch    rv103  R      30:08      1 x1-01-2\r\n",
      "        30172602_6       all   sbatch    rv103  R      30:08      1 x1-01-2\r\n"
     ]
    }
   ],
   "source": [
    "!squeue -u rv103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /data/gersbachlab/Revathy/IGVF/Jamboree/SingleCellData/logs/tagAlign.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scancel 30172600_0 30172600_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (revathy)",
   "language": "python",
   "name": "revathy_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
